#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ê³ ê¸‰ ë¶„ì„ íŒŒì´í”„ë¼ì¸
- N-gram ë¶„ì„
- ìƒë‹´ì¸ ìœ í˜•ë³„ êµì°¨ ë¶„ì„  
- ì •ì±… ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import pandas as pd
import numpy as np
from pathlib import Path
import json

from src.utils.config import load_config, ensure_output_dirs
from src.utils.text_processing import analyze_ngrams
from src.analysis.cross_analysis import CrossAnalysis
from src.analysis.policy_insights import PolicyInsights

def main():
    """ê³ ê¸‰ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 50)
    print("ê³ ê¸‰ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 50)
    
    # 1. ì„¤ì • ë¡œë“œ
    print("\n1. ì„¤ì • ë¡œë“œ ì¤‘...")
    config = load_config()
    ensure_output_dirs(config)
    
    # 2. ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
    print("\n2. ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì¤‘...")
    preprocessed_data_path = Path(config['data']['output_dir']) / "csv" / "preprocessed_data.csv"
    
    if not preprocessed_data_path.exists():
        print("ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € run_01_data_preprocessing.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    df = pd.read_csv(preprocessed_data_path)
    print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
    
    # 3. ì£¼ì œ ë°œê²¬ ê²°ê³¼ ë¡œë“œ
    print("\n3. ì£¼ì œ ë°œê²¬ ê²°ê³¼ ë¡œë“œ ì¤‘...")
    topic_results = {}
    topic_terms_path = Path(config['data']['output_dir']) / "csv" / "global_topics_top_terms.csv"
    
    if topic_terms_path.exists():
        topic_terms_df = pd.read_csv(topic_terms_path)
        topic_results['top_terms'] = {}
        
        for topic_id in topic_terms_df['topic_id'].unique():
            topic_terms = topic_terms_df[topic_terms_df['topic_id'] == topic_id]
            terms = [(row['term'], row['score']) for _, row in topic_terms.iterrows()]
            topic_results['top_terms'][topic_id] = terms
    
    # 4. í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë¡œë“œ
    print("\n4. í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë¡œë“œ ì¤‘...")
    cluster_results = {}
    cluster_summary_path = Path(config['data']['output_dir']) / "csv" / "cluster_summary.csv"
    
    if cluster_summary_path.exists():
        cluster_results['cluster_stats'] = pd.read_csv(cluster_summary_path)
    
    # 5. N-gram ë¶„ì„
    print("\n5. N-gram ë¶„ì„ ì¤‘...")
    texts = df['combined_text'].tolist()
    
    # 2-gram ë¶„ì„
    bigram_results = analyze_ngrams(texts, n=2, min_freq=1)
    
    # 3-gram ë¶„ì„
    trigram_results = analyze_ngrams(texts, n=3, min_freq=1)
    
    # N-gram ê²°ê³¼ ì €ì¥
    output_dir = Path(config['data']['output_dir']) / "csv"
    
    # 2-gram ê²°ê³¼ ì €ì¥
    bigram_df = pd.DataFrame(bigram_results['2-gram'], columns=['bigram', 'frequency'])
    bigram_df.to_csv(output_dir / "bigram_analysis.csv", index=False, encoding='utf-8-sig')
    
    # 3-gram ê²°ê³¼ ì €ì¥
    trigram_df = pd.DataFrame(trigram_results['3-gram'], columns=['trigram', 'frequency'])
    trigram_df.to_csv(output_dir / "trigram_analysis.csv", index=False, encoding='utf-8-sig')
    
    print(f"N-gram ë¶„ì„ ì™„ë£Œ:")
    print(f"  2-gram: {len(bigram_results['2-gram'])}ê°œ")
    print(f"  3-gram: {len(trigram_results['3-gram'])}ê°œ")
    
    # 6. ìƒë‹´ì¸ ìœ í˜•ë³„ êµì°¨ ë¶„ì„
    print("\n6. ìƒë‹´ì¸ ìœ í˜•ë³„ êµì°¨ ë¶„ì„ ì¤‘...")
    cross_analyzer = CrossAnalysis(config)
    cross_results = cross_analyzer.analyze_consultation_patterns(df, str(output_dir))
    
    print("êµì°¨ ë¶„ì„ ì™„ë£Œ")
    
    # 7. ì •ì±… ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
    print("\n7. ì •ì±… ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì¤‘...")
    policy_analyzer = PolicyInsights(config)
    policy_results = policy_analyzer.generate_policy_insights(
        df, topic_results, cluster_results, str(output_dir)
    )
    
    print("ì •ì±… ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì™„ë£Œ")
    
    # 8. ìµœì¢… ê²°ê³¼ ìš”ì•½
    print("\n8. ìµœì¢… ê²°ê³¼ ìš”ì•½...")
    
    print(f"\nğŸ“Š N-gram ë¶„ì„ ê²°ê³¼:")
    print(f"  ì£¼ìš” 2-gram (ìƒìœ„ 5ê°œ):")
    for i, (bigram, freq) in enumerate(bigram_results['2-gram'][:5], 1):
        print(f"    {i}. {bigram}: {freq}íšŒ")
    
    print(f"\n  ì£¼ìš” 3-gram (ìƒìœ„ 5ê°œ):")
    for i, (trigram, freq) in enumerate(trigram_results['3-gram'][:5], 1):
        print(f"    {i}. {trigram}: {freq}íšŒ")
    
    print(f"\nğŸ“ˆ êµì°¨ ë¶„ì„ ê²°ê³¼:")
    print(f"  ìƒë‹´ì¸ ìœ í˜•ë³„ ë¹ˆë„:")
    for person_type, count in cross_results['person_type_freq'].items():
        print(f"    {person_type}: {count}ê±´")
    
    print(f"\n  ì£¼ìš” íŒ¨í„´:")
    for pattern in cross_results['insights']['key_patterns']:
        print(f"    {pattern['person_type']} â†’ {pattern['main_consultation']}: {pattern['count']}ê±´")
    
    print(f"\nğŸ’¡ ì •ì±… ì¸ì‚¬ì´íŠ¸:")
    print(f"  FAQ ì œì•ˆ: {len(policy_results['faq_suggestions'])}ê°œ")
    print(f"  êµìœ¡ìë£Œ ì œì•ˆ: {len(policy_results['education_materials'])}ê°œ")
    print(f"  ê·œì•½ ê°œì„  ì œì•ˆ: {len(policy_results['regulation_improvements'])}ê°œ")
    print(f"  ë¦¬ìŠ¤í¬ ê´€ë¦¬: {len(policy_results['risk_management'])}ê°œ")
    print(f"  ìš°ì„ ìˆœìœ„ ì•¡ì…˜: {len(policy_results['priority_actions'])}ê°œ")
    
    print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜:")
    print(f"  CSV íŒŒì¼: {output_dir}")
    print(f"  ì‹œê°í™”: {Path(config['data']['output_dir']) / 'visualizations'}")
    print(f"  ì •ì±… ì¸ì‚¬ì´íŠ¸: {output_dir / 'policy_insights.json'}")
    
    print("\n" + "=" * 50)
    print("ê³ ê¸‰ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
    print("=" * 50)

if __name__ == "__main__":
    main() 